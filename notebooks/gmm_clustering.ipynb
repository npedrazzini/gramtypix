{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils.extmath import row_norms\n",
    "from sklearn.datasets._samples_generator import make_blobs\n",
    "from timeit import default_timer as timer\n",
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required input are the first two dimensions of the MDS matrix obtained from the Hamming distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mds.df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's find the optimal number of clusters/components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df[['x','y']])\n",
    "\n",
    "n_components = np.arange(1, 10)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(data)\n",
    "          for n in n_components]\n",
    "plt.plot(n_components, [m.bic(data) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(data) for m in models], label='AIC')\n",
    "\n",
    "allbics = [m.bic(data) for m in models]\n",
    "allaics = [m.aic(data) for m in models]\n",
    "minbicind = allbics.index(min([m.bic(data) for m in models]))\n",
    "minaicind = allaics.index(min([m.aic(data) for m in models]))\n",
    "\n",
    "plt.axvline(x=n_components[minbicind],c=(0,0,0),linestyle='--')\n",
    "# plt.text((n_components[minbicind] + 0.1),-2000,'min(BIC)',rotation=90)\n",
    "plt.axvline(x=n_components[minaicind],c=(0,0,0),linestyle='--')\n",
    "# plt.text((n_components[minaicind] + 0.1),-2000,'min(AIC)',rotation=90)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('AIC/BIC score')\n",
    "plt.savefig('aicbic.jpeg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "S=[]\n",
    "\n",
    "# Range of clusters to try (2 to 10)\n",
    "K=range(2,10)\n",
    "\n",
    "# Select data for clustering model\n",
    "X = data\n",
    "\n",
    "for k in K:\n",
    "    # Set the model and its parameters\n",
    "    model = GaussianMixture(n_components=k, n_init=20, init_params='kmeans', random_state=1234)\n",
    "    # Fit the model \n",
    "    labels = model.fit_predict(X)\n",
    "    # Calculate Silhoutte Score and append to a list\n",
    "    S.append(metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "\n",
    "maxsil = S.index(max(S))\n",
    "print(maxsil)\n",
    "print(S)\n",
    "\n",
    "# Plot the resulting Silhouette scores on a graph\n",
    "plt.plot(K, S, 'bo-', c=(0,0,0))\n",
    "plt.axvline(x=K[maxsil],c=(0,0,0),linestyle='--')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.savefig('silhouette.jpeg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the optimal number of clusters and generate a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = 4\n",
    "\n",
    "def get_initial_means(X, init_params, r):\n",
    "        # Run a GaussianMixture with max_iter=0 to output the initalization means\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=clus, init_params=init_params, tol=1e-9, max_iter=2000, random_state=r\n",
    "        ).fit(X)\n",
    "        return gmm.means_\n",
    "    \n",
    "r = np.random.RandomState(seed=1234)\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "start = timer()\n",
    "ini = get_initial_means(X, 'kmeans', r)\n",
    "end = timer()\n",
    "init_time = end - start\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=clus, means_init=ini, tol=1e-9, max_iter=2000, random_state=r).fit(X)\n",
    "\n",
    "labels = gmm.predict(X)\n",
    "print(labels)\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    data = X[gmm.predict(X) == i]\n",
    "    df2 = pd.DataFrame(data)\n",
    "    df2.to_csv(f'{str(i)}.csv')\n",
    "    plt.scatter(data[:, 0], data[:, 1], color=color, marker=\"x\")\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.savefig('gmm.jpeg',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can choose 4 different numbers of clusters and plot the resulting GMM models side by side to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclus = [3,4,5,6]\n",
    "\n",
    "logliks = pd.DataFrame()\n",
    "\n",
    "X = np.array(df[['x','y']])\n",
    "\n",
    "colors = [\"navy\", \"turquoise\", \"cornflowerblue\", \"darkorange\",\"darkgreen\",\"brown\"]\n",
    "times_init = {}\n",
    "relative_times = {}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4 * len(nclus) // 2, 6))\n",
    "plt.subplots_adjust(\n",
    "    bottom=0.1, top=0.9, hspace=0.15, wspace=0.05, left=0.05, right=0.95\n",
    ")\n",
    "\n",
    "for n, clus in enumerate(nclus):\n",
    "    def get_initial_means(X, init_params, r):\n",
    "        # Run a GaussianMixture with max_iter=0 to output the initalization means\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=clus, init_params=init_params, tol=1e-9, max_iter=2000, random_state=r\n",
    "        ).fit(X)\n",
    "        return gmm.means_\n",
    "    \n",
    "    r = np.random.RandomState(seed=1234)\n",
    "    plt.subplot(2, len(nclus) // 2, n + 1)\n",
    "\n",
    "    start = timer()\n",
    "    ini = get_initial_means(X, 'kmeans', r)\n",
    "    end = timer()\n",
    "    init_time = end - start\n",
    "\n",
    "    gmm = GaussianMixture(\n",
    "        n_components=clus, means_init=ini, tol=1e-9, max_iter=2000, random_state=r).fit(X)\n",
    "    \n",
    "    labels = gmm.predict(X)\n",
    "    print(labels)\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        data = X[gmm.predict(X) == i]\n",
    "        df2 = pd.DataFrame(data)\n",
    "        df2.to_csv(f'{str(i)}.csv')\n",
    "        plt.scatter(data[:, 0], data[:, 1], color=color, marker=\"x\")\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.savefig('gmm_compare.jpeg',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
